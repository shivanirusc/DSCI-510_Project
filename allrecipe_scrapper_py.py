# -*- coding: utf-8 -*-
"""allrecipe_scrapper.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1neeeTPwXWiy9si1P9Ii3_I2qqWS7dHUs
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re

# Send a GET request to the URL
url = "https://www.allrecipes.com/recipes/"
response = requests.get(url)

# Parse the HTML content
soup = BeautifulSoup(response.content, "html.parser")

# Find all links on the page
all_links = soup.find_all("a", href=True)

# Extract category URLs
category_urls = []
for link in all_links:
    href = link['href']
    if href.startswith("https://www.allrecipes.com/recipes/") and href != "https://www.allrecipes.com/recipes/":
        category_urls.append(href)

for category_url in category_urls:
    print(category_url)

# Send a GET request to the URL
recipe_urls = []
url = "https://www.allrecipes.com/recipes/17057/everyday-cooking/more-meal-ideas/5-ingredients/main-dishes/"
for category_url in category_urls:
	response = requests.get(category_url)

	soup = BeautifulSoup(response.content, "html.parser")

	all_links = soup.find_all("a", href=True)

	for link in all_links:
		href = link['href']
		if href.startswith("https://www.allrecipes.com/recipe/"):
				 recipe_urls.append(href)

for url in recipe_urls:
    print(url)

def scrape_recipe(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")

    recipe_name = soup.find("h1", class_="article-heading type--lion").get_text().strip(' \t\n\r')
    calorie_table = soup.find("table", class_ ="mntl-nutrition-facts-summary__table")

    # Extract ingredients
    ingredients = [li.get_text().strip(' \t\n\r') for li in soup.find("div", {"id": "mntl-structured-ingredients_1-0"}).find_all("li")]
    calorie = None
    if calorie_table:
        rows = calorie_table.find_all("tr")
        for row in rows:
            calorie = row.find("td", class_= "mntl-nutrition-facts-summary__table-cell type--dog-bold").get_text().strip(' \t\n\r')

    #Extract Calorie count
    calorie_table = soup.find("table", class_ ="mntl-nutrition-facts-summary__table")
    calories = None
    if calorie_table:
        rows = calorie_table.find_all("tr")
        calories = rows[0].find("td").get_text()

    # Extract nutrition table
    nutrition_data = {}
    nutrition_table = soup.find("table", class_="mntl-nutrition-facts-label__table")
    if nutrition_table:
        rows = nutrition_table.find_all("tr")
        for row in rows:
            cells = row.find_all("td")
            if len(cells) == 2:
                key = re.sub(r'\d+(\D+)', '', cells[0].get_text(strip=True))
                value = re.sub(r'\D+', '', cells[0].get_text(strip=True))
                nutrition_data[key] = value

    return {'Recipe Name': recipe_name, 'Ingredients': ', '.join(ingredients), 'Calorie': calories, **nutrition_data}

# Iterate over each URL, scrape the data, and append to the list
all_data = []
for url in recipe_urls:
    recipe_data = scrape_recipe(url)
    all_data.append(recipe_data)
df_recipe = pd.DataFrame(all_data)
df_recipe = df_recipe[['Recipe Name', 'Ingredients'] + sorted(list(df_recipe.columns.difference(['Recipe Name', 'Ingredients'])))]
df_recipe.to_csv('recipe_data.csv', index=False)
df_recipe